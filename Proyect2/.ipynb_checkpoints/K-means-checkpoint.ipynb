{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build K-Means from scratch in Python\n",
    "\n",
    " The algorithm works iteratively to assign each data point to one of *K* groups based on the features that are provided the result of k-means clustering algorithm are:\n",
    "1) The centroids of the K clusters, which can be used to label new data\n",
    "2) Labels for the training data (each data point is assigned to a single cluster)\n",
    "\n",
    "### Why use K-Means ? \n",
    "The algorithm can be used to confirm assumption about what type of group belongs some element (representative)\n",
    "Once the algorithm has been run and the groups are defined, any new data can be easily assigned to the correct group.\n",
    "\n",
    "This is a ver versatile algorithm that can be used for any type of grouping. Some examples of uses cases are : \n",
    "Behavioral segmentation : \n",
    "1) Segment by purchase history\n",
    "2) Segment by activities on application, website, or platform\n",
    "3) Define personas based on interests\n",
    "4) *Group images*\n",
    "5) Separate audio\n",
    "6) Separate valid activity groups from bots\n",
    "\n",
    "\n",
    "### The Algorithm\n",
    "K-Means is actually one of the simplest unsupervised clustering algorithm. Assume we have input data points x1,x2,x3,…,xn and value of K(the number of clusters needed). We follow the below procedure:\n",
    "\n",
    "1) Pick K points as the initial centroids from the data set, either randomly or the first K.\n",
    "2) Find the Euclidean distance of each point in the data set with the identified K points — cluster centroids.\n",
    "3) Assign each data point to the closest centroid using the distance .\n",
    "4) Find the new centroid for each cluster (K) , taking the average of the points in the same cluster\n",
    "5) Repeat 2 to 4 for a fixed number of iterations or until the centroids don't change.\n",
    "\n",
    "Mathematically speaking, if each cluster centroid is denoted by $(c_{i})$ , then each data point \\(x\\) is assigned to a cluster based on:\n",
    "\n",
    "$\n",
    "\\arg \\left( \\min_{x \\in c_i} D(c_i, x)^2 \\right)\\\n",
    "$\n",
    "\n",
    "![](img/im5.png)\n",
    "\n",
    "![](img/im6.png)\n",
    "\n",
    "### Choosing the right K\n",
    "So it's really problematic of you choose the wrong *K*, \n",
    "\n",
    "![](img/im7.png)\n",
    "\n",
    "So this was a clustering problem for 3 clusters , but if I choose K = 4 I will not given me a good accuracy of prediction .\n",
    "So you want a proper way for figuring or I would say guessing an aproximate K, to do this we have may algorithms like :\n",
    "- cross validation\n",
    "- bootstrap\n",
    "- AUC \n",
    "- BIC\n",
    "\n",
    "\n",
    "But we will discuss one of the most simple and easy to comprehend called **\"elbow point\"**\n",
    "\n",
    "The basic idea behind this algorithm is that take various values of cost \n",
    "![](img/im8.png)\n",
    "\n",
    "The Within-clusters Sum of Squares(WCSS) is a monotonous decreasing function, at the beginning WCSS is declining extremely fast at some point (**elbow point**) we are not reaching a much better solution , so 3 the biggest number of cluster for wich we are still getting a significant decrease in WCSS.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
